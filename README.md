# 🧠 Machine Learning from Scratch vs Scikit-Learn

This repository contains implementations of various **Machine Learning algorithms from scratch (using only NumPy and Python)** along with their **comparisons against Scikit-Learn (sklearn)** models.  
The goal is to understand the **mathematical intuition**, **working principles**, and **performance trade-offs** between manual and library-based implementations.

---

## 🚀 Project Overview

- ✅ Implement every major **ML algorithm from scratch** — step-by-step.
- 🔍 Compare performance and results with **Scikit-Learn equivalents**.
- 📊 Visualize training progress, accuracy, and decision boundaries.
- 🧩 Strengthen core understanding of **linear algebra**, **optimization**, and **statistics** behind ML.
- 🧠 Build intuition on how real-world ML libraries work under the hood.

## 🧩 Algorithms Covered (Ongoing)

| Category | Algorithm | Scratch Implementation | Scikit-Learn Equivalent |
|-----------|------------|------------------------|--------------------------|
| **Regression** | Linear Regression | ✅ | ✅ `LinearRegression()` |
| | Polynomial Regression | ✅ | ✅ `PolynomialFeatures` + `LinearRegression` |
| | Logistic Regression | ✅ | ✅ `LogisticRegression()` |
| **Classification** | K-Nearest Neighbors (KNN) | ✅ | ✅ `KNeighborsClassifier()` |
| | Naive Bayes | ✅ | ✅ `GaussianNB()` |
| | Support Vector Machine (SVM) | 🚧 | ✅ `SVC()` |
| | Decision Tree | 🚧 | ✅ `DecisionTreeClassifier()` |
| **Ensemble Methods** 
| | Boosting (AdaBoost=) | 🚧 | ✅ `AdaBoostClassifier()`|
