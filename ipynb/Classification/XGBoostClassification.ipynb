{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ba617df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21fbb7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    def __init__(self, depth=0):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.feature = None\n",
    "        self.threshold = None\n",
    "        self.value = None\n",
    "        self.depth = depth\n",
    "\n",
    "class XGBoostClassifierScratch:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3, \n",
    "                 min_child_weight=1, gamma=0, reg_lambda=1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.min_child_weight = min_child_weight\n",
    "        self.gamma = gamma\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.trees = []\n",
    "        self.F0 = None  # initial log-odds\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def _calc_grad_hess(self, y, pred):\n",
    "        p = self._sigmoid(pred)\n",
    "        grad = p - y\n",
    "        hess = p * (1 - p)\n",
    "        return grad, hess\n",
    "\n",
    "    def _calc_leaf_weight(self, grad, hess):\n",
    "        return -np.sum(grad) / (np.sum(hess) + self.reg_lambda)\n",
    "\n",
    "    def _calc_gain(self, G_L, H_L, G_R, H_R):\n",
    "        gain = 0.5 * (G_L**2 / (H_L + self.reg_lambda) + G_R**2 / (H_R + self.reg_lambda) -\n",
    "                      (G_L + G_R)**2 / (H_L + H_R + self.reg_lambda)) - self.gamma\n",
    "        return gain\n",
    "\n",
    "    def _build_tree(self, X, grad, hess, depth=0):\n",
    "        node = TreeNode(depth=depth)\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Stop conditions\n",
    "        if depth >= self.max_depth or n_samples <= 1:\n",
    "            node.value = self._calc_leaf_weight(grad, hess)\n",
    "            return node\n",
    "\n",
    "        best_gain = -np.inf\n",
    "        best_feature = None\n",
    "        best_thresh = None\n",
    "\n",
    "        # Try all features and thresholds\n",
    "        for f in range(n_features):\n",
    "            thresholds = np.unique(X[:, f])\n",
    "            for t in thresholds:\n",
    "                left_mask = X[:, f] <= t\n",
    "                right_mask = ~left_mask\n",
    "\n",
    "                if np.sum(left_mask) < 1 or np.sum(right_mask) < 1:\n",
    "                    continue\n",
    "\n",
    "                G_L, H_L = np.sum(grad[left_mask]), np.sum(hess[left_mask])\n",
    "                G_R, H_R = np.sum(grad[right_mask]), np.sum(hess[right_mask])\n",
    "\n",
    "                if H_L < self.min_child_weight or H_R < self.min_child_weight:\n",
    "                    continue\n",
    "\n",
    "                gain = self._calc_gain(G_L, H_L, G_R, H_R)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = f\n",
    "                    best_thresh = t\n",
    "\n",
    "        if best_gain <= 0:\n",
    "            node.value = self._calc_leaf_weight(grad, hess)\n",
    "            return node\n",
    "\n",
    "        # Otherwise, split\n",
    "        node.feature = best_feature\n",
    "        node.threshold = best_thresh\n",
    "        left_mask = X[:, best_feature] <= best_thresh\n",
    "        right_mask = ~left_mask\n",
    "        node.left = self._build_tree(X[left_mask], grad[left_mask], hess[left_mask], depth + 1)\n",
    "        node.right = self._build_tree(X[right_mask], grad[right_mask], hess[right_mask], depth + 1)\n",
    "        return node\n",
    "\n",
    "    def _predict_tree(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._predict_tree(x, node.left)\n",
    "        else:\n",
    "            return self._predict_tree(x, node.right)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Initialize F0 with log-odds\n",
    "        pos_ratio = np.clip(np.mean(y), 1e-5, 1-1e-5)\n",
    "        self.F0 = np.log(pos_ratio / (1 - pos_ratio))\n",
    "        pred = np.full(y.shape, self.F0)\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            grad, hess = self._calc_grad_hess(y, pred)\n",
    "            tree = self._build_tree(X, grad, hess)\n",
    "            self.trees.append(tree)\n",
    "            pred += self.learning_rate * np.array([self._predict_tree(x, tree) for x in X])\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        pred = np.full(X.shape[0], self.F0)\n",
    "        for tree in self.trees:\n",
    "            pred += self.learning_rate * np.array([self._predict_tree(x, tree) for x in X])\n",
    "        p = self._sigmoid(pred)\n",
    "        return np.vstack([1-p, p]).T\n",
    "\n",
    "    def predict(self, X):\n",
    "        return (self.predict_proba(X)[:, 1] >= 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea518ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scratch XGBoost Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = make_classification(n_samples=200, n_features=5, n_informative=3, n_redundant=0, random_state=42)\n",
    "xgb_clf = XGBoostClassifierScratch(n_estimators=50, learning_rate=0.1, max_depth=3, gamma=0.1)\n",
    "xgb_clf.fit(X, y)\n",
    "y_pred = xgb_clf.predict(X)\n",
    "print(\"Scratch XGBoost Accuracy:\", accuracy_score(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9084503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "sklearn_clf = XGBClassifier(n_estimators=50, learning_rate=0.1, max_depth=3, use_label_encoder=False, verbosity=0)\n",
    "sklearn_clf.fit(X, y)\n",
    "y_pred_sklearn_clf = sklearn_clf.predict(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
